#!/usr/bin/env python3
"""
Generate enriched seed.sql with historical claims for RAG functionality.

Creates 60 historical claims (completed/manual_review) with:
- 20 approve, 20 deny, 20 manual_review decisions
- Realistic OCR text for each claim type
- claim_documents with OCR results (embeddings generated by separate job)
- claim_decisions with reasoning

Plus 40 pending claims for testing.
"""

import random
from datetime import datetime, timedelta

# =============================================================================
# Realistic OCR Text Templates
# =============================================================================

AUTO_TEXTS = [
    """AUTO ACCIDENT REPORT
Date: {date}
Vehicle: {vehicle}
Damage: Rear-end collision, bumper crushed, trunk damaged
Estimated Repair Cost: ${amount}
Police Report: Filed on {date}
Other Party: Insured
Fault: Other driver (distracted driving)
Witnesses: 2 witnesses present
Photos: Attached""",
    """COLLISION CLAIM
Date: {date}
Vehicle: {vehicle}
Damage: Side impact, driver door dented, window shattered
Estimated Cost: ${amount}
Fault: Other driver ran red light
Police Report: #{report_num}
Witnesses: Yes (3)
Towing: Required to repair shop
Rental Car: Needed""",
    """AUTO THEFT REPORT
Date: {date}
Vehicle: {vehicle} - STOLEN
Location: Shopping center parking lot, 2nd level
Police Report: #{report_num}
Keys: With owner (not stolen)
Last Seen: {date} 2:30 PM
Recovery Status: Not recovered after 30 days
Value: ${amount}""",
    """VEHICLE DAMAGE CLAIM
Date: {date}
Vehicle: {vehicle}
Incident: Front-end collision with tree
Damage: Radiator damaged, airbags deployed, frame bent
Estimated Repair: ${amount}
Towing: Required
Driveable: No
Cause: Swerved to avoid deer
Weather: Rainy conditions""",
]

MEDICAL_TEXTS = [
    """MEDICAL CLAIM
Patient: {patient}
Date of Service: {date}
Diagnosis: Acute appendicitis (ICD-10: K35.80)
Procedure: Emergency appendectomy
Provider: City General Hospital
Hospital Stay: 3 days
Surgeon Fees: $8,500
Hospital Charges: ${amount}
Anesthesia: $2,200
Total: ${amount}
Prior Authorization: Emergency - not required
Insurance: Policy #{policy}""",
    """HOSPITAL BILL
Patient: {patient}
Admission Date: {date}
Discharge: {discharge_date}
Diagnosis: Fractured tibia (ICD-10: S82.401A)
Treatment: ORIF surgery, cast application
Physical Therapy: 6 sessions
Hospital Days: 2
Total Charges: ${amount}
Itemized Bill: Attached
Covered Services: Surgery, hospitalization, PT
Policy: #{policy}""",
    """MEDICAL SERVICES
Patient: {patient}
Date: {date}
Service: MRI scan - lumbar spine
Diagnosis: Herniated disc L4-L5 (ICD-10: M51.26)
Referring Physician: Dr. Johnson
Prior Authorization: #{auth_num} - Approved
Facility: Advanced Imaging Center
Charges: ${amount}
Medical Necessity: Chronic back pain, failed conservative treatment""",
    """EMERGENCY ROOM VISIT
Patient: {patient}
Date: {date}
Chief Complaint: Severe chest pain
Diagnosis: Anxiety attack (ICD-10: F41.0)
Treatment: Observation, EKG, cardiac enzymes
Tests: EKG, blood work, chest X-ray
Duration: 4 hours
Discharge: Stable, follow-up with PCP
Charges: ${amount}
Covered: Emergency care""",
]

HOME_TEXTS = [
    """PROPERTY DAMAGE CLAIM
Date of Loss: {date}
Property Address: {address}
Cause of Loss: Burst pipe - kitchen
Affected Areas: Kitchen, living room, basement
Water Damage: Floors, drywall, cabinets
Estimated Repairs: ${amount}
Emergency Services: Plumber called, water extraction done
Temporary Repairs: Completed
Photos: 25 photos attached
Contractor Estimate: Attached""",
    """BURGLARY REPORT
Date: {date}
Property: {address}
Police Report: #{report_num}
Items Stolen:
- 55" Samsung TV: $1,200
- MacBook Pro laptop: $2,500
- Jewelry (gold necklace, rings): $3,800
- Cash: $500
Total Value: ${amount}
Entry Method: Broken rear window
Locks Changed: Yes - {date}
Security: No alarm system""",
    """WIND DAMAGE CLAIM
Date of Storm: {date}
Property: {address}
Weather Event: Severe thunderstorm with 70mph winds
Damage:
- Roof: 45 shingles blown off
- Fence: 20 feet collapsed
- Tree: Fell on garage
Emergency Repairs: Roof tarped on {date}
Estimated Repairs: ${amount}
Weather Service Report: Attached
Contractor: ABC Roofing - estimate attached""",
    """FIRE DAMAGE CLAIM
Date of Fire: {date}
Property Address: {address}
Cause: Grease fire in kitchen
Fire Department Report: #{report_num}
Damage Assessment:
- Kitchen: Total loss
- Living Room: Smoke damage
- Bedrooms: Smoke damage
Estimated Repairs: ${amount}
Temporary Housing: Required
Fire Marshal Report: Accidental""",
]

LIFE_TEXTS = [
    """LIFE INSURANCE DEATH BENEFIT CLAIM
Policy Number: {policy}
Insured: {insured}
Date of Death: {date}
Cause of Death: Natural causes - cardiac arrest
Death Certificate: Attached (Certified copy)
Beneficiary: {beneficiary} (Spouse)
Policy Face Value: $500,000
Premium Status: All premiums current
Contestability Period: Passed (policy 5 years old)
Required Documents: Complete""",
    """DEATH BENEFIT CLAIM
Policy: {policy}
Deceased: {insured}
Date of Death: {date}
Cause: Cancer - stage 4 pancreatic
Beneficiaries: {beneficiary} (Children - equal shares)
Claim Amount: $500,000
Documentation:
- Death certificate (certified)
- Beneficiary identification
- Claim form (completed)
Policy Status: In force
Last Premium: Paid {premium_date}""",
]

# Vehicle/patient/address lists for variety
VEHICLES = ["2019 Toyota Camry", "2020 Honda Accord", "2018 Ford F-150", "2021 Tesla Model 3",
           "2017 Chevrolet Malibu", "2022 Subaru Outback", "2019 Nissan Altima", "2020 BMW 330i"]
ADDRESSES = ["123 Oak Street, Chicago IL", "456 Maple Ave, Austin TX", "789 Pine Road, Seattle WA",
            "321 Elm Drive, Boston MA", "654 Cedar Lane, Denver CO"]
PATIENTS = ["John Smith", "Mary Johnson", "Robert Davis", "Sarah Wilson", "Michael Brown",
           "Jennifer Garcia", "David Martinez", "Linda Anderson"]
BENEFICIARIES = ["Jane Smith", "Robert Johnson Jr.", "Emily Davis", "Tom Wilson", "Lisa Brown"]


def generate_claim_data(claim_num, claim_type, user_id, decision_type):
    """Generate realistic claim data including OCR text and decision reasoning."""
    base_date = datetime(2024, 1, 1) + timedelta(days=random.randint(0, 365))

    # Select and format OCR text template
    if claim_type == "Auto":
        text = random.choice(AUTO_TEXTS)
        amount = random.randint(2000, 15000)
        formatted_text = text.format(
            date=base_date.strftime("%Y-%m-%d"),
            vehicle=random.choice(VEHICLES),
            amount=amount,
            report_num=f"2024{random.randint(10000, 99999)}"
        )
    elif claim_type == "Medical":
        text = random.choice(MEDICAL_TEXTS)
        amount = random.randint(3000, 25000)
        policy = f"MED-{user_id}-2024"
        auth_num = f"AUTH{random.randint(100000, 999999)}"
        discharge = base_date + timedelta(days=random.randint(1, 5))
        formatted_text = text.format(
            date=base_date.strftime("%Y-%m-%d"),
            patient=random.choice(PATIENTS),
            amount=amount,
            policy=policy,
            auth_num=auth_num,
            discharge_date=discharge.strftime("%Y-%m-%d")
        )
    elif claim_type == "Home":
        text = random.choice(HOME_TEXTS)
        amount = random.randint(5000, 50000)
        formatted_text = text.format(
            date=base_date.strftime("%Y-%m-%d"),
            address=random.choice(ADDRESSES),
            amount=amount,
            report_num=f"2024{random.randint(10000, 99999)}"
        )
    else:  # Life
        text = random.choice(LIFE_TEXTS)
        amount = 500000
        policy = f"LIF-{user_id}-{random.randint(1000, 9999)}"
        premium_date = (base_date - timedelta(days=random.randint(30, 60))).strftime("%Y-%m-%d")
        formatted_text = text.format(
            date=base_date.strftime("%Y-%m-%d"),
            insured=random.choice(PATIENTS),
            policy=policy,
            beneficiary=random.choice(BENEFICIARIES),
            premium_date=premium_date
        )

    # Generate decision reasoning
    if decision_type == "approve":
        reasons = [
            f"Claim validated and approved. All required documentation complete. Coverage confirmed under policy terms. Incident falls within covered perils. Amount ${amount} authorized for payment.",
            f"Valid claim. Policy was active at time of incident. Documentation meets all requirements. No exclusions apply. Approved for payment: ${amount}.",
            f"Claim approved. Coverage verified against policy schedule. Supporting documents adequate. Medical necessity established. Payment authorized: ${amount}.",
            f"Approval granted. Incident covered under policy. All deductibles and co-pays calculated correctly. No red flags identified. Claim amount: ${amount} approved.",
        ]
        confidence = round(random.uniform(0.85, 0.98), 2)
    elif decision_type == "deny":
        reasons = [
            f"Claim denied. Exclusion clause applies - this type of incident is not covered under policy terms. Amount ${amount} is not payable.",
            f"Denied. Incident occurred outside coverage period. Policy was not active on the date of loss. Cannot process claim for ${amount}.",
            f"Claim rejected. Pre-existing condition exclusion applies. Similar claim was denied previously. Not covered per policy section 4.2.",
            f"Denial issued. Lack of required documentation. Repeated requests for information not fulfilled. Cannot validate claim for ${amount}.",
        ]
        confidence = round(random.uniform(0.75, 0.92), 2)
    else:  # manual_review
        reasons = [
            f"Claim flagged for manual review. Amount ${amount} exceeds automatic approval threshold of $20,000. Senior adjuster review required.",
            f"Manual review needed. Documentation incomplete - awaiting additional medical records and itemized billing. Cannot auto-process claim for ${amount}.",
            f"Flagged for expert assessment. Unusual circumstances require specialist review. Policy interpretation needed for coverage determination.",
            f"Requires manual intervention. Potential fraud indicators detected. Claims investigator assigned. Hold on ${amount} payment pending review.",
        ]
        confidence = round(random.uniform(0.50, 0.75), 2)

    reasoning = random.choice(reasons)
    processing_time = random.randint(15000, 120000)  # 15s to 2min
    ocr_confidence = round(random.uniform(0.88, 0.99), 2)

    return {
        'ocr_text': formatted_text,
        'reasoning': reasoning,
        'confidence': confidence,
        'ocr_confidence': ocr_confidence,
        'processing_time': processing_time,
        'processed_at': (base_date + timedelta(hours=random.randint(1, 48))).strftime("%Y-%m-%d %H:%M:%S"),
        'decided_at': (base_date + timedelta(hours=random.randint(1, 48))).strftime("%Y-%m-%d %H:%M:%S"),
        'ocr_processed_at': (base_date + timedelta(minutes=random.randint(5, 30))).strftime("%Y-%m-%d %H:%M:%S"),
    }


def escape_sql(text):
    """Escape single quotes for SQL."""
    return text.replace("'", "''")


def generate_enriched_seed():
    """Generate complete enriched seed.sql file."""

    # Read original seed.sql to get users, contracts, and knowledge_base
    with open("/Users/mouchan/projects/agentic-claim-demo/helm/agentic-claims-demo/files/cm.init-postgres/seed.sql", "r") as f:
        original_seed = f.read()

    # Extract sections we want to keep
    users_start = original_seed.find("-- ============================================================================\n-- 50 USERS")
    contracts_start = original_seed.find("-- ============================================================================\n-- CONTRACTS")
    claims_start = original_seed.find("-- ============================================================================\n-- 100 CLAIMS")
    kb_start = original_seed.find("-- ============================================================================\n-- KNOWLEDGE BASE")

    users_section = original_seed[users_start:contracts_start].strip()
    contracts_section = original_seed[contracts_start:claims_start].strip()
    kb_section = original_seed[kb_start:].strip()

    # Generate historical claims distribution
    # 20 Auto, 20 Medical, 15 Home, 5 Life
    # Each with ~1/3 approve, deny, manual_review
    historical_claims = []

    # 20 Auto claims
    for i in range(20):
        if i < 7:
            decision = "approve"
        elif i < 14:
            decision = "deny"
        else:
            decision = "manual_review"
        historical_claims.append(("Auto", decision))

    # 20 Medical claims
    for i in range(20):
        if i < 7:
            decision = "approve"
        elif i < 14:
            decision = "deny"
        else:
            decision = "manual_review"
        historical_claims.append(("Medical", decision))

    # 15 Home claims
    for i in range(15):
        if i < 5:
            decision = "approve"
        elif i < 10:
            decision = "deny"
        else:
            decision = "manual_review"
        historical_claims.append(("Home", decision))

    # 5 Life claims
    historical_claims.extend([
        ("Life", "approve"),
        ("Life", "deny"),
        ("Life", "deny"),
        ("Life", "manual_review"),
        ("Life", "manual_review")
    ])

    # Shuffle to randomize order
    random.seed(42)  # For reproducibility
    random.shuffle(historical_claims)

    # Start building the new seed.sql
    sql = """-- Enriched seed data for Claims Demo
-- 64 users, 100 claims (60 historical + 40 pending)
-- Historical claims have processed status, OCR text, and decisions for RAG

-- Delete existing data
DELETE FROM claim_decisions;
DELETE FROM guardrails_detections;
DELETE FROM processing_logs;
DELETE FROM claim_documents;
DELETE FROM claims;
DELETE FROM knowledge_base;
DELETE FROM user_contracts;
DELETE FROM users;

"""

    # Add users section
    sql += users_section + "\n\n"

    # Add contracts section
    sql += contracts_section + "\n\n"

    # Generate claims section header
    sql += """-- ============================================================================
-- 100 CLAIMS (60 Historical + 40 Pending)
-- ============================================================================
"""

    # Read original claims to get claim details (user_id, type, dates, etc.)
    claims_text = original_seed[claims_start:kb_start]
    claims_lines = [line for line in claims_text.split('\n') if line.startswith("('USR")]

    # Parse original claim data
    original_claims = []
    for line in claims_lines:
        parts = line.strip("(),").split("', '")
        if len(parts) >= 6:
            user_id = parts[0].strip("'")
            claim_num = parts[1]
            claim_type = parts[2]
            doc_path = parts[3]
            status = parts[4]
            submitted = parts[5].strip("'),")
            original_claims.append({
                'user_id': user_id,
                'claim_number': claim_num,
                'claim_type': claim_type,
                'document_path': doc_path,
                'submitted_at': submitted
            })

    # Generate INSERT for claims table
    sql += "INSERT INTO claims (user_id, claim_number, claim_type, document_path, status, submitted_at, processed_at, total_processing_time_ms) VALUES\n"

    claim_values = []
    claim_documents = []
    claim_decisions = []

    # First 60: Historical claims
    for idx in range(60):
        claim = original_claims[idx]
        claim_type_for_historical, decision = historical_claims[idx]

        # Override claim type to match historical distribution
        claim['claim_type'] = claim_type_for_historical

        # Generate data
        data = generate_claim_data(idx + 1, claim_type_for_historical, claim['user_id'], decision)

        status = "completed" if decision in ["approve", "deny"] else "manual_review"

        claim_values.append(
            f"('{claim['user_id']}', '{claim['claim_number']}', '{claim_type_for_historical}', '{claim['document_path']}', "
            f"'{status}', '{claim['submitted_at']}', '{data['processed_at']}', {data['processing_time']})"
        )

        # claim_documents entry
        claim_doc = f"""INSERT INTO claim_documents (claim_id, document_type, file_path, raw_ocr_text, ocr_confidence, ocr_processed_at, language)
SELECT id, 'pdf', '{claim['document_path']}', '{escape_sql(data['ocr_text'])}', {data['ocr_confidence']}, '{data['ocr_processed_at']}', 'eng'
FROM claims WHERE claim_number = '{claim['claim_number']}';"""
        claim_documents.append(claim_doc)

        # claim_decisions entry
        decision_type_enum = decision  # approve, deny, manual_review
        requires_manual = "true" if decision == "manual_review" else "false"

        claim_decision = f"""INSERT INTO claim_decisions (claim_id, decision, confidence, reasoning, llm_model, requires_manual_review, decided_at)
SELECT id, '{decision_type_enum}', {data['confidence']}, '{escape_sql(data['reasoning'])}',
       'llama-3-3-70b-instruct', {requires_manual}, '{data['decided_at']}'
FROM claims WHERE claim_number = '{claim['claim_number']}';"""
        claim_decisions.append(claim_decision)

    # Next 40: Pending claims (61-100)
    for idx in range(60, 100):
        claim = original_claims[idx]
        claim_values.append(
            f"('{claim['user_id']}', '{claim['claim_number']}', '{claim['claim_type']}', '{claim['document_path']}', "
            f"'pending', '{claim['submitted_at']}', NULL, NULL)"
        )

    sql += ",\n".join(claim_values) + ";\n\n"

    # Add claim_documents inserts
    sql += "-- ============================================================================\n"
    sql += "-- CLAIM DOCUMENTS (Historical claims only - embeddings generated by job)\n"
    sql += "-- ============================================================================\n"
    sql += "\n".join(claim_documents) + "\n\n"

    # Add claim_decisions inserts
    sql += "-- ============================================================================\n"
    sql += "-- CLAIM DECISIONS (Historical claims only)\n"
    sql += "-- ============================================================================\n"
    sql += "\n".join(claim_decisions) + "\n\n"

    # Add knowledge base section
    sql += kb_section + "\n"

    return sql


if __name__ == "__main__":
    print("Generating enriched seed.sql...")
    seed_sql = generate_enriched_seed()

    output_path = "/Users/mouchan/projects/agentic-claim-demo/helm/agentic-claims-demo/files/cm.init-postgres/seed-enriched.sql"
    with open(output_path, "w") as f:
        f.write(seed_sql)

    print(f"âœ“ Generated {output_path}")
    print(f"  Total size: {len(seed_sql):,} bytes")
    print(f"  60 historical claims with OCR text and decisions")
    print(f"  40 pending claims for testing")
